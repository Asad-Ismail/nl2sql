{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3ede45-7f5f-42c5-9ccf-6b6983ef47d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy\n",
      "  Using cached dspy-3.0.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting backoff>=2.2 (from dspy)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: joblib~=1.3 in /opt/conda/lib/python3.12/site-packages (from dspy) (1.5.2)\n",
      "Collecting openai>=0.28.1 (from dspy)\n",
      "  Using cached openai-2.13.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: regex>=2023.10.3 in /opt/conda/lib/python3.12/site-packages (from dspy) (2025.11.3)\n",
      "Requirement already satisfied: orjson>=3.9.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (3.11.4)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /opt/conda/lib/python3.12/site-packages (from dspy) (4.67.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (2.32.5)\n",
      "Requirement already satisfied: optuna>=3.4.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (2.12.3)\n",
      "Collecting magicattr>=0.1.6 (from dspy)\n",
      "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting litellm>=1.64.0 (from dspy)\n",
      "  Downloading litellm-1.80.10-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (5.6.3)\n",
      "Collecting json-repair>=0.30.0 (from dspy)\n",
      "  Downloading json_repair-0.54.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.12/site-packages (from dspy) (9.1.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from dspy) (4.11.0)\n",
      "Collecting asyncer==0.0.8 (from dspy)\n",
      "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (5.5.2)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (3.1.2)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/conda/lib/python3.12/site-packages (from dspy) (14.2.0)\n",
      "Requirement already satisfied: pillow>=10.1.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (1.26.4)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from dspy) (3.6.0)\n",
      "Collecting gepa==0.0.17 (from gepa[dspy]==0.0.17->dspy)\n",
      "  Downloading gepa-0.0.17-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio->dspy) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->dspy) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/conda/lib/python3.12/site-packages (from anyio->dspy) (4.15.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (3.13.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (8.3.0)\n",
      "Collecting fastuuid>=0.13.0 (from litellm>=1.64.0->dspy)\n",
      "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: grpcio<1.68.0,>=1.62.3 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (1.67.1)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (6.10.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (1.2.1)\n",
      "Collecting tiktoken>=0.7.0 (from litellm>=1.64.0->dspy)\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.28.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.22.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy) (0.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy) (3.23.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai>=0.28.1->dspy) (1.9.0)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=0.28.1->dspy)\n",
      "  Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from optuna>=3.4.0->dspy) (1.17.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.12/site-packages (from optuna>=3.4.0->dspy) (6.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from optuna>=3.4.0->dspy) (2.0.44)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy) (1.3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.31.0->dspy) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.31.0->dspy) (1.26.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=13.7.1->dspy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=13.7.1->dspy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy) (3.2.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading dspy-3.0.4-py3-none-any.whl (285 kB)\n",
      "Downloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Downloading gepa-0.0.17-py3-none-any.whl (110 kB)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading json_repair-0.54.3-py3-none-any.whl (29 kB)\n",
      "Downloading litellm-1.80.10-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
      "Downloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
      "Using cached openai-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: magicattr, json-repair, jiter, gepa, fastuuid, backoff, tiktoken, asyncer, openai, litellm, sentence-transformers, dspy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [dspy]2m11/12\u001b[0m [dspy]nce-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed asyncer-0.0.8 backoff-2.2.1 dspy-3.0.4 fastuuid-0.14.0 gepa-0.0.17 jiter-0.12.0 json-repair-0.54.3 litellm-1.80.10 magicattr-0.1.6 openai-2.13.0 sentence-transformers-5.2.0 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install dspy sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f91519c-81aa-49e8-aa7d-c0ed1cbd8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dspy.teleprompt import KNNFewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ef54729-011a-46f0-b83e-9bea4e9e66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(\n",
    "    model=\"openai/TheBloke/CodeLlama-7B-Instruct-AWQ\",\n",
    "    api_base=\"http://localhost:8000/v1\",\n",
    "    api_key=\"dummy\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.0\n",
    ")\n",
    "dspy.configure(lm=lm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b09c748-6210-4fe6-9cc1-40ab36e7df63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: What is the capital of France? | continent: Europe\n",
      "question: What is the capital of Belgium? | continet: Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Predicted Answer: Brussels\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import numpy as np\n",
    "from dspy.teleprompt import KNNFewShot\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "qa = dspy.ChainOfThought(\"question -> answer\")\n",
    "\n",
    "trainset = [\n",
    "    dspy.Example(question=\"What is the capital of France?\",continent=\"Europe\", answer=\"Paris\").with_inputs(\"question\",\"continent\"),\n",
    "    dspy.Example(question=\"What is the capital of Pakistan?\",continent=\"Asia\", answer=\"Islamabad\").with_inputs(\"question\",\"continent\"),\n",
    "    dspy.Example(question=\"What is color of sky?\",continent=\"None\", answer=\"blue\").with_inputs(\"question\",\"continent\"),\n",
    "    dspy.Example(question=\"What is capital of Germany?\",continent=\"Europe\", answer=\"Berlin\").with_inputs(\"question\",\"continent\")\n",
    "]\n",
    "\n",
    "# Must return a numpy array, NOT a list\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def vectorizer_func(texts: list[str]):\n",
    "    print(texts[0])\n",
    "    return embedding_model.encode(texts) \n",
    "\n",
    "# 5. Initialize KNNFewShot\n",
    "# We pass the trainset HERE. It is stored inside the object.\n",
    "knn_teleprompter = KNNFewShot(\n",
    "    k=2, \n",
    "    trainset=trainset, \n",
    "    vectorizer=vectorizer_func\n",
    ")\n",
    "\n",
    "compiled_qa = knn_teleprompter.compile(qa)\n",
    "\n",
    "# 7. Run\n",
    "result = compiled_qa(question=\"What is the capital of Belgium?\",continet=\"Europe\")\n",
    "print(f\"Predicted Answer: {result.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1bd064d-4698-48b5-a98d-08171f6fa7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-18T21:36:21.174411]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of France?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "]]\n",
      "The capital of France is Paris.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Paris\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is capital of Germany?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "]]\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Berlin\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of Belgium?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The capital of Belgium is Brussels.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Brussels\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "000d7019-a2a0-460b-acf7-fe2a384e7545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]2025/12/18 21:54:33 WARNING dspy.predict.predict: Not all input fields were provided to module. Present: ['question']. Missing: ['db_schema'].\n",
      " 50%|█████     | 1/2 [00:15<00:15, 15.99s/it]2025/12/18 21:54:49 WARNING dspy.predict.predict: Not all input fields were provided to module. Present: ['question']. Missing: ['db_schema'].\n",
      "100%|██████████| 2/2 [00:27<00:00, 13.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Generated SQL: SELECT email FROM users WHERE id = 5\n",
      "\n",
      "--- Inspecting the Prompt ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-18T21:55:16.676736]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `db_schema` (str): \n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `sql` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## db_schema ## ]]\n",
      "{db_schema}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## sql ## ]]\n",
      "{sql}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Convert natural language to SQL based on the given schema.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Find the email of user 1\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "]]\n",
      "To find the email of user 1, we need to query the `users` table and select the `email` column for the row where the `id` column is equal to 1.\n",
      "\n",
      "[[ ## sql ## ]]\n",
      "SELECT email FROM users WHERE id = 1\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "How many users are there?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "]]\n",
      "To find the number of users, we need to count the number of rows in the `users` table.\n",
      "\n",
      "[[ ## sql ## ]]\n",
      "SELECT COUNT(*) FROM users\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## db_schema ## ]]\n",
      "CREATE TABLE users (id INT, name TEXT, email TEXT);\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the email for user id 5?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## sql ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To find the email for user id 5, we need to query the `users` table and select the `email` column for the row where the `id` column is equal to 5.\n",
      "\n",
      "[[ ## sql ## ]]\n",
      "SELECT email FROM users WHERE id = 5\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class TextToSQL(dspy.Signature):\n",
    "    \"\"\"Convert natural language to SQL based on the given schema.\"\"\"\n",
    "    db_schema = dspy.InputField() \n",
    "    question = dspy.InputField()\n",
    "    sql = dspy.OutputField()\n",
    "\n",
    "# 3. Define the Training Data (The \"Not Schema\" Part)\n",
    "# CRITICAL TRICK: We intentionally OMIT 'db_schema' from these examples.\n",
    "# DSPy will simply print \"Question: ... SQL: ...\" in the prompt, which is what you want.\n",
    "# We also set .with_inputs(\"question\") so the Indexer knows to focus on that.\n",
    "trainset = [\n",
    "    dspy.Example(question=\"How many users are there?\", sql=\"SELECT count(*) FROM users\").with_inputs(\"question\"),\n",
    "    dspy.Example(question=\"Find the email of user 1\", sql=\"SELECT email FROM users WHERE id = 1\").with_inputs(\"question\"),\n",
    "    dspy.Example(question=\"List all product names\", sql=\"SELECT name FROM products\").with_inputs(\"question\"),\n",
    "]\n",
    "\n",
    "# 4. Define Custom Vectorizer (The \"Embedding\" Part)\n",
    "# This handles the Test Time issue where 'db_schema' is passed but we must ignore it.\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def questions_only_vectorizer(texts: list[str]):\n",
    "    cleaned_texts = []\n",
    "    for text in texts:\n",
    "        # DSPy formats inputs like: \"db_schema: ... | question: ...\"\n",
    "        # We use regex to find \"question: \" and take everything after it.\n",
    "        match = re.search(r\"question:\\s*(.+)\", text, re.IGNORECASE)\n",
    "        if match:\n",
    "            # Found the question part! Embed only this.\n",
    "            cleaned_texts.append(match.group(1))\n",
    "        else:\n",
    "            # Fallback: if 'question:' isn't found (rare), embed the whole thing\n",
    "            cleaned_texts.append(text)\n",
    "            \n",
    "    return embedding_model.encode(cleaned_texts)\n",
    "\n",
    "# 5. Initialize & Compile\n",
    "# We pass our custom vectorizer here\n",
    "knn_teleprompter = KNNFewShot(\n",
    "    k=2, \n",
    "    trainset=trainset, \n",
    "    vectorizer=questions_only_vectorizer\n",
    ")\n",
    "\n",
    "module = dspy.ChainOfThought(TextToSQL)\n",
    "compiled_sql = knn_teleprompter.compile(module)\n",
    "\n",
    "# 6. Run it\n",
    "# At test time, we MUST provide db_schema, but our vectorizer will ignore it\n",
    "my_schema = \"CREATE TABLE users (id INT, name TEXT, email TEXT);\"\n",
    "query = \"What is the email for user id 5?\"\n",
    "\n",
    "result = compiled_sql(db_schema=my_schema, question=query)\n",
    "\n",
    "# 7. Verification\n",
    "print(f\"Generated SQL: {result.sql}\")\n",
    "print(\"\\n--- Inspecting the Prompt ---\")\n",
    "# You will see the schema is in the 'Main' part, but the Few-Shot examples ONLY have Question/SQL\n",
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8625b7e-aba7-4ce8-aa84-393fecb69bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
